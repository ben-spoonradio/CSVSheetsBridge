#!/usr/bin/env python3
"""
ì‹¤ì œ Data_dua.csv í˜•ì‹ì— ë§ì¶˜ Appsflyer ë°ì´í„° ìë™í™” ìŠ¤í¬ë¦½íŠ¸
"""

import argparse
import sys
import os
from pathlib import Path
from datetime import datetime
import logging

# src ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
src_dir = current_dir / 'src'
sys.path.insert(0, str(src_dir))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('appsflyer_automation_real.log')
    ]
)
logger = logging.getLogger(__name__)

# ëª¨ë“ˆ import
try:
    from appsflyer_processor_adapted import AppsflyerDataProcessorAdapted
    from sheets_updater import SheetsUpdater
    from dotenv import load_dotenv
except ImportError as e:
    logger.error(f"í•„ìˆ˜ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print("âŒ í•„ìˆ˜ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. src/ ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ë“¤ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class AppsflyerRealDataAutomation:
    """ì‹¤ì œ Data_dua.csv í˜•ì‹ìš© Appsflyer ë°ì´í„° ìë™í™” ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.processor = None
        self.updater = None
        self.setup_logging()

    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        # ê²°ê³¼ ë¡œê·¸ìš© ë³„ë„ ë¡œê±°
        self.result_logger = logging.getLogger('automation_results_real')
        handler = logging.FileHandler('automation_results_real.log')
        formatter = logging.Formatter('%(asctime)s - %(message)s')
        handler.setFormatter(formatter)
        self.result_logger.addHandler(handler)
        self.result_logger.setLevel(logging.INFO)

    def validate_environment(self):
        """í™˜ê²½ ì„¤ì • ê²€ì¦"""
        logger.info("í™˜ê²½ ì„¤ì • ê²€ì¦ ì‹œì‘")

        required_env_vars = [
            'GOOGLE_SHEETS_WEB_APP_URL',
            'GOOGLE_SHEETS_SHEET_ID'
        ]

        missing_vars = []
        for var in required_env_vars:
            if not os.getenv(var):
                missing_vars.append(var)

        if missing_vars:
            logger.error(f"ëˆ„ë½ëœ í™˜ê²½ë³€ìˆ˜: {missing_vars}")
            print("âŒ ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
            for var in missing_vars:
                print(f"   - {var}")
            print("\n.env íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return False

        logger.info("í™˜ê²½ ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        return True

    def analyze_csv_structure(self, csv_path: str):
        """CSV êµ¬ì¡° ë¶„ì„ ë° ì¶œë ¥"""
        try:
            import pandas as pd
            df = pd.read_csv(csv_path, encoding='utf-8-sig', nrows=5)

            print("ğŸ“Š CSV íŒŒì¼ êµ¬ì¡° ë¶„ì„")
            print("=" * 50)
            print(f"íŒŒì¼: {csv_path}")
            print(f"ì´ í–‰ ìˆ˜: {len(pd.read_csv(csv_path, encoding='utf-8-sig'))} í–‰")
            print(f"ì»¬ëŸ¼ ìˆ˜: {len(df.columns)} ê°œ")
            print("\nì»¬ëŸ¼ ëª©ë¡:")
            for i, col in enumerate(df.columns, 1):
                print(f"  {i}. {col}")

            print("\nìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):")
            for i, row in df.head(3).iterrows():
                print(f"  í–‰ {i+2}: {row.iloc[0]} | ${row.iloc[1] if len(row) > 1 else 'N/A'}")

            print()

        except Exception as e:
            print(f"âš ï¸ CSV êµ¬ì¡° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def process_data(self, csv_path: str) -> tuple:
        """ë°ì´í„° ì²˜ë¦¬"""
        logger.info(f"ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {csv_path}")
        print(f"ğŸ“Š ì‹¤ì œ Appsflyer ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {csv_path}")

        try:
            # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(csv_path):
                raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

            # CSV êµ¬ì¡° ë¶„ì„
            self.analyze_csv_structure(csv_path)

            # ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            self.processor = AppsflyerDataProcessorAdapted(csv_path)

            # ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰
            print("   ğŸ”„ ë°ì´í„° ë¡œë”© ë° ì •ì œ ì¤‘...")
            processed_data = self.processor.process()

            print("   âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")

            # ìš”ì•½ í†µê³„ ìƒì„±
            stats = self.processor.get_summary_stats()

            # ê²°ê³¼ ë¡œê¹…
            self.result_logger.info(f"Data processing completed - {stats.get('total_contents', 0)} contents processed")

            return processed_data, stats

        except Exception as e:
            logger.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise

    def update_sheets(self, processed_data, stats, backup=False):
        """Google Sheets ì—…ë°ì´íŠ¸"""
        logger.info("Google Sheets ì—…ë°ì´íŠ¸ ì‹œì‘")
        print("ğŸ“¤ Google Sheets ì—…ë°ì´íŠ¸ ì‹œì‘...")

        try:
            # Sheets ì—…ë°ì´í„° ì´ˆê¸°í™”
            self.updater = SheetsUpdater()

            # ë°±ì—… ìˆ˜í–‰ (ì„ íƒì )
            if backup:
                print("   ğŸ’¾ í˜„ì¬ ë°ì´í„° ë°±ì—… ì¤‘...")
                backup_result = self.updater.backup_current_data()
                if backup_result.get('success'):
                    print(f"   âœ… ë°±ì—… ì™„ë£Œ: {backup_result['backup_sheet']}")
                else:
                    print(f"   âš ï¸ ë°±ì—… ì‹¤íŒ¨: {backup_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

            # ëª¨ë“  ì‹œíŠ¸ ì—…ë°ì´íŠ¸
            print("   ğŸ”„ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘...")
            update_results = self.updater.update_all_sheets(processed_data, stats)

            # ê²°ê³¼ ì¶œë ¥
            if update_results['overall_success']:
                print("   âœ… ëª¨ë“  ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì„±ê³µ!")
                success_count = update_results['summary']['successful_sheets']
                total_count = update_results['summary']['total_sheets']
                print(f"   ğŸ“Š ì—…ë°ì´íŠ¸ëœ ì‹œíŠ¸: {success_count}/{total_count}")
            else:
                print("   âš ï¸ ì¼ë¶€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                # ê°œë³„ ê²°ê³¼ ì¶œë ¥
                for sheet_type, result in update_results['individual_results'].items():
                    status = "âœ…" if result.get('success') else "âŒ"
                    error_msg = result.get('error', 'Success')
                    if len(str(error_msg)) > 50:
                        error_msg = str(error_msg)[:47] + "..."
                    print(f"     {status} {sheet_type}: {error_msg}")

            # ê²°ê³¼ ë¡œê¹…
            self.result_logger.info(f"Sheets update completed - Success: {update_results['overall_success']}")

            return update_results

        except Exception as e:
            logger.error(f"Google Sheets ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ Google Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise

    def print_summary_stats(self, stats):
        """ìš”ì•½ í†µê³„ ì¶œë ¥"""
        print("\nğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)

        print(f"ì´ ê´‘ê³  ìˆ˜: {stats.get('total_contents', 0):,}ê°œ")
        print(f"ì´ ë¹„ìš©: ${stats.get('total_cost', 0):,.2f}")
        print(f"ì´ ì„¤ì¹˜ ìˆ˜: {stats.get('total_installs', 0):,}ê°œ")
        print(f"ì´ D1 ìœ ì§€ ìœ ì €: {stats.get('total_d1_retained_users', 0):,}ëª…")

        # KPI í‰ê· 
        avg_cac = stats.get('avg_d1_retained_cac', 0)
        if avg_cac and avg_cac != float('inf'):
            print(f"í‰ê·  D1 Retained CAC: ${avg_cac:.2f}")

        avg_cpi = stats.get('avg_cpi', 0)
        if avg_cpi:
            print(f"í‰ê·  CPI: ${avg_cpi:.2f}")

        avg_ctr = stats.get('avg_ctr', 0)
        if avg_ctr:
            print(f"í‰ê·  CTR: {avg_ctr:.2f}%")

        # ë§¤ì²´ë³„ ë¶„í¬
        media_dist = stats.get('media_distribution', {})
        if media_dist:
            print(f"\nğŸ“± ë§¤ì²´ë³„ ë¶„í¬:")
            for media, count in media_dist.items():
                print(f"  {media}: {count:,}ê°œ")

        # ì½˜í…ì¸  í…Œë§ˆë³„ ë¶„í¬
        theme_dist = stats.get('content_theme_distribution', {})
        if theme_dist:
            print(f"\nğŸ­ ì½˜í…ì¸  í…Œë§ˆë³„ ë¶„í¬:")
            for theme, count in theme_dist.items():
                print(f"  {theme}: {count:,}ê°œ")

        # ì„±ê³¼ ë“±ê¸‰ ë¶„í¬
        grade_dist = stats.get('performance_grade_distribution', {})
        if grade_dist:
            print(f"\nğŸ† ì„±ê³¼ ë“±ê¸‰ ë¶„í¬:")
            for grade, count in grade_dist.items():
                print(f"  {grade}ë“±ê¸‰: {count:,}ê°œ")

        # ìƒìœ„ ì„±ê³¼ì
        top_performers = stats.get('top_performers', [])
        if top_performers:
            print(f"\nğŸ¥‡ ìƒìœ„ ì„±ê³¼ ê´‘ê³  (Top 5):")
            for i, performer in enumerate(top_performers[:5], 1):
                cac = performer.get('d1_retained_cac', 0)
                cac_str = f"${cac:.2f}" if cac != float('inf') else "N/A"
                cost = performer.get('cost', 0)
                installs = performer.get('installs', 0)
                d1_users = performer.get('d1_retained_users', 0)

                # ê´‘ê³ ëª… ì¶•ì•½ (ë„ˆë¬´ ê¸¸ë©´)
                ad_name = performer.get('content_name', 'N/A')
                if len(ad_name) > 60:
                    ad_name = ad_name[:57] + "..."

                print(f"  {i}. {ad_name}")
                print(f"     ë§¤ì²´: {performer.get('media_type', 'N/A')} | í…Œë§ˆ: {performer.get('content_theme', 'N/A')} | ë“±ê¸‰: {performer.get('performance_grade', 'N/A')}")
                print(f"     ë¹„ìš©: ${cost:,.2f} | ì„¤ì¹˜: {installs:,}ê°œ | D1ìœ ì§€: {d1_users:,}ëª… | D1 CAC: {cac_str}")
                print()

    def run(self, csv_path: str, backup: bool = False, export_csv: bool = False):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        start_time = datetime.now()

        print("ğŸš€ ì‹¤ì œ Appsflyer ë°ì´í„° ìë™í™” ì‹œì‘")
        print("=" * 70)

        try:
            # 1. í™˜ê²½ ê²€ì¦
            if not self.validate_environment():
                return False

            # 2. ë°ì´í„° ì²˜ë¦¬
            processed_data, stats = self.process_data(csv_path)

            # 3. Google Sheets ì—…ë°ì´íŠ¸
            update_results = self.update_sheets(processed_data, stats, backup)

            # 4. CSV ë‚´ë³´ë‚´ê¸° (ì„ íƒì )
            if export_csv:
                output_path = f"processed_data_dua_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                self.processor.export_to_csv(output_path)
                print(f"ğŸ“„ ì²˜ë¦¬ëœ ë°ì´í„° CSV ì €ì¥: {output_path}")

            # 5. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            self.print_summary_stats(stats)

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            end_time = datetime.now()
            duration = end_time - start_time

            print(f"\nâ±ï¸ ì‹¤í–‰ ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ")
            print(f"ğŸ”— Google Sheets: https://docs.google.com/spreadsheets/d/{os.getenv('GOOGLE_SHEETS_SHEET_ID')}")

            print(f"\nğŸ‰ Data_dua.csv ìë™í™” ì™„ë£Œ!")
            print("ğŸ“Š ìƒì„±ëœ ì‹œíŠ¸ë“¤:")
            print("   - ë©”ì¸ë°ì´í„°: ì „ì²´ ê´‘ê³  ë°ì´í„° ë° KPI")
            print("   - ìš”ì•½: í†µê³„ ìš”ì•½ ë° ë¶„í¬")
            print("   - ìƒìœ„ì„±ê³¼: Top 10 ê´‘ê³  ë­í‚¹")
            print("   - í”¼ë²—í…Œì´ë¸”: ë§¤ì²´ë³„ ì„±ê³¼ êµì°¨ ë¶„ì„")

            # ìµœì¢… ê²°ê³¼ ë¡œê¹…
            self.result_logger.info(
                f"Real data automation completed successfully - Duration: {duration.total_seconds():.1f}s, "
                f"Contents: {stats.get('total_contents', 0)}, "
                f"Sheets updated: {update_results['overall_success']}"
            )

            return True

        except Exception as e:
            logger.error(f"ìë™í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            print(f"\nâŒ ìë™í™” ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            end_time = datetime.now()
            duration = end_time - start_time
            print(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ")

            # ì˜¤ë¥˜ ë¡œê¹…
            self.result_logger.error(f"Real automation failed - Error: {str(e)}, Duration: {duration.total_seconds():.1f}s")

            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='ì‹¤ì œ Data_dua.csv í˜•ì‹ìš© Appsflyer ë°ì´í„° ìë™í™” ìŠ¤í¬ë¦½íŠ¸',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python appsflyer_automation_real.py --csv Data_dua.csv
  python appsflyer_automation_real.py --csv Data_dua.csv --backup --export
        """
    )

    parser.add_argument(
        '--csv',
        type=str,
        help='ì‹¤ì œ Data_dua.csv íŒŒì¼ ê²½ë¡œ',
        default='Data_dua.csv'
    )

    parser.add_argument(
        '--backup',
        action='store_true',
        help='ì—…ë°ì´íŠ¸ ì „ í˜„ì¬ ë°ì´í„° ë°±ì—…'
    )

    parser.add_argument(
        '--export',
        action='store_true',
        help='ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°'
    )

    parser.add_argument(
        '--verbose',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )

    args = parser.parse_args()

    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # ìë™í™” ì‹¤í–‰
    automation = AppsflyerRealDataAutomation()
    success = automation.run(
        csv_path=args.csv,
        backup=args.backup,
        export_csv=args.export
    )

    # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()